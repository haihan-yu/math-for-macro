\documentclass[letterpaper,12pt,leqno]{article}
\usepackage{paper,math,notes}
\available{https://www.pascalmichaillat.org/t3.html}
\hypersetup{pdftitle={Differential Equations}}

\begin{document}

\title{Differential Equations}
\author{Pascal Michaillat}
\date{}

\begin{titlepage}
\maketitle
\tableofcontents
\end{titlepage}

\section{First-Order Differential Equations}\label{sec:one}

\subsection{Constant Growth Rate}

Let $x(t)$ be a function of time $t\in\R$. Let \[\dot{x}(t)\equiv dx/dt\] denote the derivative of $x(t)$ with respect to time. 

Consider the equation 
\begin{equation}
\dot{x}(t) -\l\cdot x(t) = 0
\label{eq:FODE1}\end{equation}
where $\l\in\R$ is a constant. Equation~\eqref{eq:FODE1} is a \textit{first-order differential equation} (FODE), because it involves $x(t)$ and the first-order derivative of $x(t)$ with respect to time: $\dot{x}(t)$.  Equation~\eqref{eq:FODE1} is a functional equation: the unknown is the function $x(t)$ rather than a number or a vector. Solving equation~\eqref{eq:FODE1} means finding the functions $x(t)$ that, together with their derivative $\dot{x}(t)$, satisfy equation~\eqref{eq:FODE1} for all $t \in \R$.

Equation~\eqref{eq:FODE1} is an especially simple differential equation. It can be rewritten as 
\[\frac{\dot{x}(t)}{x(t)}= \l,\]
so it imposes that $x(t)$ has a constant growth rate $\l$ over time. It admits a simple class of functions as solution:
\begin{equation}
x(t) =A\cdot  e^{\l \cdot t} \label{eq:FODE1sol},
\end{equation}
for any constant $A\in \R$. Furthermore, the constant $A$ can be determined by an additional boundary condition because
\[A=x(0)=x(t_{0})\cdot e^{-\l \cdot t_{0}}\]
for any date $t_{0}\in \R$.

It is clear that functions of the type~\eqref{eq:FODE1sol} satisfy equation~\eqref{eq:FODE1}. We now show that if a function $x(t)$ solves equation~\eqref{eq:FODE1}, it is necessarily of the type~\eqref{eq:FODE1sol}.
Observe that
\begin{equation*}
\frac{\dot{x}(t)}{x(t)}=\od{\ln{x(t)}}{t},
\end{equation*}
which allows us to rewrite differential equation~\eqref{eq:FODE1} as 
\begin{equation*}
\frac{d\ln x(t)}{dt}=\l
\end{equation*}
Let $t_{0}\in\R$. Integrating the equation from $t_{0}$ to $t$, $x(t)$ necessarily satisfies
\begin{align*}
\int_{t_{0}}^{t} d\ln x(t)&=\int_{t_{0}}^{t} \l\cdot dt\\
\ln{x(t)} -\ln{ x\bp{t_{0}}}& =\l \bp{t-t_{0}}\\
x(t)&=x(t_{0})\cdot  e^{\l \cdot(t-t_{0})}=\bs{x(t_{0})\cdot e^{-\l \cdot t_{0}}}\cdot e^{\l \cdot t}.
\end{align*}
Therefore, if $x(t)$ solves equation~\eqref{eq:FODE1}, it is necessarily of the type~\eqref{eq:FODE1sol}.

 
\subsection{Constant Coefficient}

We have solved the simplest FODE, which takes the form of equation~\eqref{eq:FODE1}. We now study a more general FODE: 
\begin{equation}
\dot{x}(t)-\l \cdot x(t) =f(t),\label{eq:FODE2}
\end{equation}
where $f(t)\in \R$. Equation~\eqref{eq:FODE1} is the special case of equation~\eqref{eq:FODE2} with $f(t)=0$ for all $t$.

Equation~\eqref{eq:FODE2} admits a simple class of functions as solution:
\begin{equation}
x(t)=e^{\l \cdot t} \cdot \bs{A+\int_{0}^{t}f(z) \cdot e^{-\l \cdot z} dz} \label{eq:FODE2sol}
\end{equation}
for any constant $A\in \R$. Furthermore, the constant $A$ can be determined by an additional boundary condition because
\[A=x(0)=x(t_{0})\cdot e^{-\l \cdot t_{0}}-\int_{0}^{t_{0}}f(z) \cdot e^{-\l \cdot z} dz\]
for any date $t_{0}\in \R$.

It is clear that functions of the type~\eqref{eq:FODE2sol} satisfy equation~\eqref{eq:FODE2}. We now show that if a function $x(t)$ solves equation~\eqref{eq:FODE2}, it is necessarily of the type~\eqref{eq:FODE2sol}.

To be able to solve the FODE, we manipulate a certain function $x(t)\cdot \mu(t)$ instead of manipulating $x(t)$ directly. The auxiliary function $\mu(t) $ is called the \textit{integrating factor}. The integrating factor for this problem is 
\[\mu(t) =e^{-\l \cdot t}.\]
This integrating factor $\mu(t)$ has the desirable property that $\dot{\mu}(t) =-\l \cdot \mu(t)$.

We multiply both sides of the differential equation~\eqref{eq:FODE2} by the integrating factor to obtain
\begin{align*}
\dot{x}(t) \cdot \mu(t) -\l \cdot x(t)\cdot  \mu(t) & =f(t) \cdot \mu(t)\\
\dot{x}(t) \cdot\mu(t) +x(t) \cdot\dot{\mu}(t) &=f(t)\cdot \mu(t)\\
\od{\bs{x(t) \cdot \mu(t)}}{t}& =f(t) \cdot\mu(t).
\end{align*}
Integrating the equation from $t_{0}\in \R$ to $t$ we obtain
\begin{align}
\int_{t_{0}}^{t} d\bs{x(t) \cdot \mu(t)}&=\int_{t_{0}}^{t}f(z) \cdot \mu(z) dz\nonumber\\
x(t)\cdot \mu(t)-x(t_{0})\cdot \mu\bp{t_{0}}&=\int_{t_{0}}^{t}f(z)\cdot  \mu(z) dz\nonumber\\
x(t)& =\frac{x\bp{t_{0}} \cdot \mu\bp{t_{0}}+\int_{t_{0}}^{t}f(z) \cdot \mu(z) dz}{\mu(t)}.\label{eq:INTER}
\end{align}
Given the definition of the integrating factor $\mu(t)$, 
\begin{align*}
x(t)& =e^{\l \cdot t} \cdot \bs{x\bp{t_{0}} \cdot e^{-\l\cdot t_{0}}+\int_{t_{0}}^{t}f(z) \cdot e^{-\l \cdot z} dz}.
\end{align*}
Therefore, there exists $A\in \R$ such that 
\begin{align*}
x(t)& =e^{\l \cdot t} \cdot \bs{A+\int_{0}^{t}f(z) \cdot e^{-\l \cdot z} dz} .
\end{align*}

\subsection{General Case}

We now generalize~\eqref{eq:FODE2} to allow the coefficient $\l$ to vary with time $t$. We solve
\begin{equation}
\dot{x}(t) -\l(t) \cdot x(t) =f(t),\label{eq:FODE3}
\end{equation}
with $\l(t)\in \R$ and  $f(t)\in \R$. 

Equation~\eqref{eq:FODE3} admits the following class of functions as solution:
\begin{equation}
x(t)=\exp{\int_{0}^{t}\l(s) ds} \cdot \bs{A+\int_{0}^{t}f(z) \cdot \exp{-\int_{0}^{z}\l(s)ds} dz} \label{eq:FODE3sol}
\end{equation}
for any constant $A\in \R$. Furthermore, the constant $A$ can be determined by an additional boundary condition because
\[A=x(0)=x(t_{0})\cdot \exp{-\int_{0}^{t_{0}}\l(s)ds}-\int_{0}^{t_{0}}f(z) \cdot \exp{-\int_{0}^{z}\l(s)ds} dz\]
for any date $t_{0}\in \R$.

Some algebra shows that functions of the type~\eqref{eq:FODE3sol} satisfy equation~\eqref{eq:FODE3}. We now show that if a function $x(t)$ solves equation~\eqref{eq:FODE3}, it is necessarily of the type~\eqref{eq:FODE3sol}. As above, we introduce an integrating factor. The integrating factor for this problem is
\begin{equation*}
\mu(t) =\exp \bp{-\int_{0}^{t}\l(s) ds}.
\end{equation*}
This integrating factor $\mu(t)$ has the desirable property that 
\[\dot{\mu}(t) =-\l(t) \cdot \mu(t).\]

We multiply both sides of equation~\eqref{eq:FODE3} by the integrating factor to obtain
\begin{align*}
\dot{x}(t) \cdot \mu(t) -\l(t) \cdot  \mu(t) \cdot x(t)& =f(t) \cdot \mu(t)\\
\dot{x}(t) \cdot\mu(t) +x(t) \cdot \dot{\mu}(t) &=f(t)\cdot \mu(t)\\
\od{\bs{x(t) \cdot \mu(t)}}{t}& =f(t) \cdot\mu(t).
\end{align*}
Integrating the equation from $t_{0}\in \R$ to $t$ we obtain as earlier equation~\eqref{eq:INTER}. Therefore the solution to equation~\eqref{eq:FODE3} is necessarily of the type~\eqref{eq:FODE3sol}.

\subsection{Initial Value Problem}
Often, an initial condition for $x(t) $ is given:
\begin{equation}
x\bp{t_{0}} =x_{0}.  \label{eq:ic}
\end{equation}
Equation~\eqref{eq:FODE3} together with equation~\eqref{eq:ic} form an \textit{initial value problem}. The constant $A$ in~\eqref{eq:FODE3sol} must satisfy
\[A=x_{0}\cdot \exp{-\int_{0}^{t_{0}}\l(s)ds}-\int_{0}^{t_{0}}f(z) \cdot \exp{-\int_{0}^{z}\l(s)ds} dz.\]
Hence the solution to the initial value problem is
\begin{equation}
x(t) =x_{0}\cdot \exp{\int_{t_{0}}^{t}\l(s)ds}+\int_{t_{0}}^{t}f(z)\cdot \exp{\int_{z}^{t}\l(s)ds}dz.\label{eq:icsol}
\end{equation}

\section{Linear Systems of First-Order Differential Equations}\label{sec:two}

We often encounter dynamic systems with several variables that move together over time. For example in the consumption-saving problem that we solved with optimal control methods, in the case of CRRA utility, the solution is characterized by two FODEs:
\begin{align*}
\dot{a}(t) &=r\cdot a(t)-c(t), \\
\dot{c}(t) &=\frac{r-\rho}{\g}\cdot  c(t).
\end{align*}
The first FODE is the asset accumulation equation and the second FODE is the Euler equation that characterizes optimal consumption over time. To solve explicitly for the optimal consumption path, we need to solve the two FODEs
simultaneously. This section presents a method to solve systems of FODEs.


We consider a system of $n$ FODEs with constant coefficients:
\begin{align*}
\dot{x}_{1}(t) &=A_{11}\cdot x_{1}(t)+A_{12}\cdot x_{2}(t)+\ldots+A_{1n}\cdot x_{n}(t) +f_{1}(t) \\
\dot{x}_{2}(t) &=A_{21}\cdot x_{1}(t)+A_{22}\cdot x_{2}(t)+\ldots+A_{2n}\cdot x_{n}(t) +f_{2}(t) \\
&. \\
&. \\
&. \\
\dot{x}_{n}(t) &=A_{n1}\cdot x_{1}(t)+A_{n2}\cdot x_{2}(t)+\ldots+A_{nn}\cdot x_{n}(t) +f_{n}(t).
\end{align*}
Our goal is to solve for the $n$ functions $x_{1}(t)$, $x_{2}(t),\ldots, x_{n}(t)$.

An alternative way of expressing the system is to write it in matrix form:
\begin{equation}
\bm{\dot{x}}(t) =\bm{A}  \bm{x}(t) +\bm{f}(t), \label{eq:FODEsys}
\end{equation}
where $\bm{\dot{x}}(t) \in \R^{n}$, $\bm{x}(t) \in \R^{n}$, and $\bm{f}(t) \in \R^{n}$ are column vectors with $n$ elements. $\bm{A}\in \R^{n\times n}$ is a constant $n\times n$ matrix. The system of FODEs is linear because it can be written in matrix form: it involves a linear relationship between the vector $\bm{\dot{x}}(t)$ and the vector $\bm{x}(t)$.

If $\bm{A}$ is diagonal ($A_{ij}=0$ for all $i\neq j$), the system would reduce to a collection of $n$ FODEs---one FODE for each  $x_{i}(t)$---that can be solved independently using the techniques from Section~\ref{sec:one}.
If $\bm{A}$ is not diagonal, the different entries in $\bm{x}(t)$ interact and we must solve the system of FODEs simultaneously.

\subsection{General Solution}

Assume that $\bm{A}$ is diagonalizable. There exists $\bm{V}\in \R^{n\times n}$ such that
\begin{equation}
\bm{A}=\bm{V}\bm{\Lambda}\bm{V}^{-1},\label{eq:DECO}
\end{equation}
where $\bm{\Lambda}\in \R^{n\times n}$ is a diagonal matrix. The diagonal entries of $\bm{\Lambda}$ are the $n$ eigenvalues $\l_{1},\ldots,\l_{n}$ of $\bm{A},$ and $\bm{V}$ is the matrix whose
columns are the eigenvectors $\bm{z}_{1},\ldots,\bm{z}_{n}$ of $\bm{A}$. 

By definition, $\l_{1},\ldots,\l_{n}$ are the $n$ roots of the polynomial equation
\begin{equation*}
\det( \bp{\bm{A}-\l \bm{I}} =0.
\end{equation*}
For any $i=1,\dots,n$, the eigenvector $\bm{z}_{i}$ associated with the eigenvalue $\l_{i}$ satisfies 
\begin{equation*}
\bp{\bm{A}-\l_{i} \bm{I}} \bm{z}_{i} =\bm{0}.
\end{equation*}


Using the decomposition~\eqref{eq:DECO}, we rewrite the system \eqref{eq:FODEsys} as
\begin{align}
\bm{V}^{-1}\bm{\dot{x}}(t) &=\bm{\Lambda} \bm{V}^{-1}\bm{x}(t) +\bm{V}^{-1}\bm{f}(t)\nonumber\\
\bm{\dot{y}}(t) &=\bm{\Lambda} \bm{y}(t) +\bm{g}(t) ,  \label{eq:FODEsyst}
\end{align}
where we define
\begin{align*}
\bm{y}(t) &\equiv \bm{V}^{-1}\bm{x}(t)\\
\bm{g}(t) &\equiv \bm{V}^{-1}\bm{f}(t).
\end{align*}
Since the matrix $\bm{\Lambda}$ is diagonal, the system is reduced to a collection of $n$ independent FODEs---one for each $y_{i}(t)$. Once we have solved for $\bm{y}(t)$, we can recover $\bm{x}(t)$ by 
\begin{equation*}
\bm{x}(t) =\bm{V} \bm{y}(t) .
\end{equation*}
The nature of the eigenvalues and corresponding eigenvectors determines the dynamics of the solution.

\subsection{Homogenous Systems}

If $\bm{f}(t) =\bm{0}$, the system \eqref{eq:FODEsys} is \textit{homogenous}; otherwise it is \textit{nonhomogenous}. 

For homogenous systems, 
\begin{equation}
\bm{\dot{x}}(t) =\bm{A} \bm{x}(t).  \label{eq:FODEsysh}
\end{equation}
So the transformed system~\eqref{eq:FODEsyst} becomes 
\begin{equation*}
\bm{\dot{y}}(t) =\bm{\Lambda}\bm{y}(t) ,
\end{equation*}
which leads to $n$ independent FODEs:
\begin{equation*}
\dot{y}_{i}(t) -\l_{i} \cdot y_{i}(t)=0
\end{equation*}
for $i=1,\ldots,n$. In other words, each $y_{i}(t) $ is growing at constant rate $\l_{i}$. The analysis of Section~\ref{sec:one} shows that the solution to the $i^{th}$ FODE is 
\begin{equation*}
y_{i}(t) =A_{i}\cdot e^{\l_{i}\cdot t}
\end{equation*}
where $A_{i}\in \R$ is a constant. Finally, $x_{1}(t),\ldots,x_{n}(t)$ are given by
\begin{equation*}
\bm{x}(t) =\bm{V} \bm{y}(t) .
\end{equation*}
The columns of $\bm{V}$ are the eigenvectors $\bm{z}_{1},\ldots,\bm{z}_{n}$ corresponding to the
eigenvalues $\l_{1},...\l_{n}$. Hence the solution of the homogenous system~\eqref{eq:FODEsysh} is 
\begin{equation}
\bm{x}(t) =A_{1}\cdot \bm{z}_{1} \cdot e^{\l_{1}\cdot t}+\ldots+A_{n}\cdot \bm{z}_{n}\cdot e^{\l_{n}\cdot t}.\label{eq:SOLEV}
\end{equation}
The nature of the eigenvalues and the corresponding eigenvectors determines
the dynamics of the solution. 

\subsection{Example: Two-Variable Homogenous System}
Consider a two-variable homogenous system
\begin{align*}
\dot{x}_{1}(t) &=a\cdot x_{1}(t)+b\cdot x_{2}(t) \\
\dot{x}_{2}(t) &=c\cdot x_{1}(t)+d\cdot x_{2}(t).
\end{align*}
We can write it in matrix form
\begin{equation*}
\bm{\dot{x}}(t) =\bm{A} \bm{x}(t)
\end{equation*}
where the matrix $\bm{A}$ is 
\begin{equation*}
\bm{A}=\bs{
\begin{array}{ll}
a & b \\ 
c & d
\end{array}}.
\end{equation*}
Assume $\det(\bm{A}) =a\cdot d-b\cdot c\neq 0. $

\subsubsection{Closed-Form Solution}
Equation~\eqref{eq:SOLEV} implies that to determine a closed-form solution of this homogenous system, we need to find the eigenvalues and eigenvectors of the matrix $\bm{A}$.

The eigenvalues are solutions to 
\begin{align*}
\det( \bp{\bm{A}-\l \bm{I}} &=0\\
\bp{a-\l} \cdot \bp{d-\l} -b\cdot c &=0 \\
\l ^{2}-\bp{a+d}\cdot  \l +\bp{a\cdot d-b\cdot c} &=0.
\end{align*}
Note that the product of the two eigenvalues is equal to the determinant of $
\bm{A}$:
\begin{equation}
\l_{1}\cdot \l_{2}=a\cdot d-b\cdot c=\det(\bm{A}).\label{eq:DETL}
\end{equation}

Let $\bs{
\begin{array}{l}
\a_{1} \\ 
\b_{1}
\end{array}
} $ be the eigenvector correspond to $\l_{1}$ and $\bs{
\begin{array}{l}
\a_{2} \\ 
\b_{2}
\end{array}} $ be the eigenvector correspond to $\l_{2}$. These vectors are solutions to 
\begin{equation*}
\bp{\bm{A}-\l_{i}\bm{I}} \bs{
\begin{array}{l}
\a_{i} \\ 
\b_{i}
\end{array}} =0
\end{equation*}
which yields the system
\begin{align*}
\bp{a-\l_{i}}\cdot  \a_{i}+b\cdot \b _{i} &=0 \\
c\cdot \a_{i}+\bp{d-\l_{i}}\cdot  \b _{i} &=0.
\end{align*}

Consider the cases where the eigenvalues are real and distinct, the general
solution~\eqref{eq:SOLEV} implies
\begin{align*}
x_{1}(t) &=A_{1}\cdot \a_{1}\cdot e^{\l_{1}\cdot t}+A_{2}\cdot \a_{2}\cdot e^{\l_{2}\cdot t}\\
x_{2}(t) &=A_{1}\cdot \b_{1}\cdot e^{\l_{1}\cdot t}+A_{2}\cdot \b_{2}\cdot e^{\l_{2}\cdot t} 
\end{align*}
where $A_{1}$ and $A_{2}$ are arbitrary constants. 

Note that in the case in which $\l_{1}=\l_{2}=\l$, the system $\bs{x_{1}(t),x_{2}(t)}$ above is still the general solution of the system of FODEs as long as the two eigenvectors $\bs{\a_{1},\b_{1}}$ and $\bs{\a_{2},\b_{2}}$ are linearly independent.

Also note that any nonhomogenous system with constant terms $\bs{\k_{1},\k_{2}}$:
\begin{align*}
\dot{x}_{1}(t) &=a\cdot x_{1}(t)+b\cdot x_{2}(t)+\k_{1} \\
\dot{x}_{2}(t) &=c\cdot x_{1}(t)+d\cdot x_{2}(t)+\k_{2},
\end{align*}
can be transformed into an homogenous system.


\subsubsection{Stability}

Now that we have found a closed-form solution to the system, we can analyze its stability. There are three cases.

\begin{itemize}

\item  $\l_{1}<0$ and $\l_{2}<0$: As shown by~\eqref{eq:DETL}, since $\l_{1}$ and $\l_{2}$ have the same sign, $\det(\bm{A}) >0$. As $t\to +\infty$, $x_{1}(t)\to 0$ and $x_{2}(t)\to 0$. The system is \textit{stable}. The origin is called a \textit{sink}.

\item $\l_{1}>0$ and $\l_{2}>0$: As shown by~\eqref{eq:DETL}, since $\l_{1}$ and $\l_{2}$ have the same sign, $\det(\bm{A}) >0$. As $t\to +\infty$, $|x_{1}(t)|\to +\infty$ and $|x_{2}(t)|\to +\infty$. The system is \textit{unstable}. The origin is called a \textit{source}.

\item $\l_{1}$ and $\l_{2}$ have opposite sign: As shown by~\eqref{eq:DETL}, since $\l_{1}$ and $\l_{2}$ have opposite sign, $\det(\bm{A}) <0$. One part of the solution is stable (it converges to 0 at $t\to +\infty$), the other is unstable (it converges to $\infty$ at $t\to +\infty$). The origin $(0,0)$ is called a \textit{saddle point}.

\end{itemize}

\section{Phase Diagrams}\label{sec:three}

Without solving for eigenvalues and eigenvectors explicitly, we can study the properties of a linear system of FODEs by drawing its \textit{phase diagram}. 

\subsection{Construction of the Phase Diagram}

Consider the following linear nonhomogenous system of two FODEs:
\begin{align}
\dot{x}_{1}(t) &=a\cdot x_{1}(t)+b\cdot x_{2}(t)+\k_{1} \label{eq:nonh1}\\
\dot{x}_{2}(t) &=c\cdot x_{1}(t)+d\cdot x_{2}(t)+\k_{2},\label{eq:nonh2}
\end{align}
with $a<0$, $b<0$, $c<0$, $d>0$, $\k_{1}>0$, and $\k_{2}>0$. Since $a\cdot d-b\cdot c<0$, the eigenvalues of the system are of opposite sign. We are in a \textit{saddle-point equilibrium}.

We construct the phase diagram as follows:

\begin{itemize}

\item Compute the two loci $\dot{x}_{1}=0$ and $\dot{x}_{2}=0$. The locus for $\dot{x}_{1}=0$ is given by
\begin{align*}
x_{2}=-\frac{a}{b}\cdot x_{1}-\frac{\k_{1}}{b}.
\end{align*}
The locus is a straight line with a negative slope in the $(x_{1},x_{2})$ plan. The locus  for $\dot{x}_{2}=0$ is given by
\begin{align*}
x_{2}=-\frac{c}{d}\cdot x_{1}-\frac{\k_{2}}{d}.
\end{align*}
The locus is a straight line with positive slope in the $(x_{1},x_{2})$ plan.

\item The intersection of the two loci is the \textit{steady-state solution}. Denote the intersection of the two loci as $\bp{x_{1}^{*},x_{2}^{*}} $. These two loci divide the $(x_{1},x_{2})$ plane into four areas.

\item From~\eqref{eq:nonh1}, $\dot{x}_{1}$ is decreasing in $x_{2}$ because $b<0$. Thus any point above the $\dot{x}_{1}=0$ line must have $\dot{x}_{1}<0$ and any point below the $\dot{x}_{1}=0$ line must have $\dot{x}_{1}>0$. We represent these properties by an horizontal arrow pointing west for any point above the $\dot{x}_{1}=0$ line and an horizontal arrow pointing east for any point below the $\dot{x}_{1}=0$ line. 

Similarly, from \eqref{eq:nonh2}, $\dot{x}_{2}$ is increasing in $x_{2}$ because $d>0$. Thus any point above the $\dot{x}_{2}=0$ line must have $\dot{x}_{2}>0$ and any point below the $\dot{x}_{2}=0$ line must have $\dot{x}_{2}<0$. We represent these properties by a vertical arrow pointing north for any point above the $\dot{x}_{2}=0$ line and a vertical arrow pointing south for any point below the $\dot{x}_{2}=0$ line. 

These sets of arrows are called \textit{streamlines}. They determine the trajectories of the system at any point in all the
four areas. 

\item Last, we derive the saddle path for the system. We know that such a saddle path exist because the eigenvalues of the system have opposite sign. 

\end{itemize}

Drawing the phase diagram of a two-variable system is useful to understand the main features of the dynamic system without solving for $x_{1}(t) $ and $x_{2}(t) $ explicitly. The phase diagram is represented at the end of the lecture notes.


\subsection{Diagram with a State and a Control Variable}

Suppose $x_{1}$ is a state variable: information revealed at $t$ does not influence its value at $t$. Suppose $x_{2}$ is a control variable: information revealed at $t$ may influence its value at $t$. Suppose that we are in the steady state $\bp{x_{1}^{*},x_{2}^{*}}$ of the previous phase diagram.

Assume that there is an exogenous, unanticipated increase in $\k_{2}$. This increase is revelation of news because it is an unanticipated change to one of the parameters or variables of the system. As $\k_{2}$ increases, the $\dot{x}_{2}=0$ locus shifts down, so the new steady state $\bp{x_{1}^{* *},x_{2}^{* *}} $ is to the south-east of the previous steady state: $x_{1}^{* *}>x_{1}^{*}$ and $x_{2}^{* *}<x_{2}^{*}.$ There is also a new saddle path passing through this new steady state.

Where do we start after the news is revealed at $t=t_{r}$? That is, what are $x_{1}\bp{t_{r}}$ and $x_{2}\bp{t_{r}}$? Since $x_{1}$ is the state variable, it cannot respond to the news, and $x_{1}\bp{t_{r}} =x_{1}^{*}$. For the system to
converge to the new steady state, it must arrive at the steady-state level $x_{1}^{* *}$ of the state variable along the new saddle path. So $x_{2}\bp{t_{r}} $ must be on the new saddle path at $x_{1}^{*}$, and over time both $x_{1}(t) $ and $x_{2}(t) $ move along the saddle path until they converge to the new steady state. To sum up, the system jumps from $\bp{x_{1}^{*},x_{2}^{*}}$ to $\bp{x_{1}^{*},x_{2}\bp{t_{r}}} $, and then moves along the saddle path until it reaches $\bp{x_{1}^{* *},x_{2}^{* *}}$.

The response to the news in the phase diagram is represented at the end of the lecture notes.

\section{Nonlinear Systems of First-Order Differential Equations}

Unlike the systems of FODEs studied in sections~\ref{sec:two} and~\ref{sec:three}, which were linear, systems of FODEs in macroeconomics are often nonlinear. For example the typical growth model is characterized by the following nonlinear system of FODEs:
\begin{align}
\dot{k}(t) &=f\bp{k(t)} -c(t)-\d \cdot k(t),  \label{eq:growth1} \\
\dot{c}(t) &=\bs{f'\bp{k(t)} -\bp{\d+\rho}}\cdot c(t), \label{eq:growth2}
\end{align}
where $\rho >0$,and $\d \in \bp{0,1}$ are parameters, the capital stock $k(t)$ is a state variable
with $k_{0}$ given, and the production function $f$ satisfies the Inada conditions:
\begin{align*}
f\bp{0}=0,\; f'>0,\;f''<0,\;\lim_{k\to +\infty}f'(k)=0,\;\lim_{k\to 0}f'(k) =+\infty.
\end{align*}
It is difficult to solve this system explicitly. But without solving it explicitly, we can characterize its properties by constructing its phase diagram. This is what we do in this section.

\subsection{Construction of the Phase Diagram}

We draw the phase diagram in a plane with the state variable $k$ on the x-axis and the control variable $c$ on the y-axis. We proceed as follows:

\begin{itemize}

\item We draw the $\dot{k}=0$ curve defined by
\begin{align*}
c=f\bp{k} -\d\cdot k
\end{align*}
and the $\dot{c}=0$ curve defined by
\begin{align*}
f^{\prime}\bp{k} =\d +\rho.
\end{align*}
The $\dot{k}=0$ curve is concave and the $\dot{c}=0$ curve is a vertical line in the $(k,c)$ plane.

\item The intersection of these two loci is the steady state $(k^{*},c^{*})$ of the system.

\item To determine the directions of the streamlines, we partially differentiate equations~\eqref{eq:growth1} and~\eqref{eq:growth2}: 
\begin{align*}
\pd{\dot{k}}{c} &=-1<0 \\
\pd{\dot{c}}{k} &=c\cdot f''(k)<0.
\end{align*}
Therefore as $c$ increases, $\dot{k}$ decreases. So, the horizontal arrows point eastward below the $\dot{k}=0$ curve and westward above it. Similarly as $k$ increases, $\dot{c}$ decreases. So the vertical arrows point northward to the left of the $\dot{c}=0$ curve and southward to the right of it.

\item The streamlines drawn yield a saddle-point equilibrium at the steady state $(k^{*},c^{*})$. The only way for the economy to converge to the steady state is on the saddle path leading to it. This means that given any initial capital $k_{0}$, initial consumption $c_{0}$ is such that the pair $\bp{k_{0},c_{0}} $
lies on the saddle path.

\end{itemize}

The phase diagram is represented at the end of the lecture notes.

\subsection{Linearization}

The streamlines suggest that we are in a saddle-point equilibrium. We can check the validity of the conclusion by linearizing the nonlinear system~\eqref{eq:growth1}--\eqref{eq:growth2} using a first-order Taylor expansion around the steady state:
\begin{align*}
\dot{k} &=\dot{k}^{*} +\bp{k-k^{*}} \cdot \pd{\dot{k}}{k}+\bp{c-c^{*}}\cdot \pd{\dot{k}}{c} \\
\dot{c} &=\dot{c}^{*} +\bp{k-k^{*}}\cdot  \pd{\dot{c}}{k}+\bp{c-c^{*}}\cdot \pd{\dot{c}}{c}.
\end{align*}
Given that $\dot{k}^{*} =\dot{c}^{*} =0,$ we have 
\begin{equation*}
\bs{\begin{array}{l}
\dot{k}\\ 
\dot{c}
\end{array}} =\bm{J}^{*}\bs{
\begin{array}{l}
k-k^{*} \\ 
c-c^{*}
\end{array}},
\end{equation*}
where $\bm{J}^{*}$ is the Jacobian matrix evaluated at the steady state:
\begin{equation*}
\bm{J}^{*}=\bs{
\begin{array}{ll}
\pdw{\dot{k}}{k}{(k^{*},c^{*})}  & \pdw{\dot{k}}{c}{(k^{*},c^{*})} \\ 
\pdw{\dot{c}}{k}{(k^{*},c^{*})} & \pdw{\dot{c}}{c}{(k^{*},c^{*})}
\end{array}}.
\end{equation*}
This system is a two-variable nonhomogenous system of FODEs
for \[\bm{x}=\bs{\begin{array}{l}
k\\ 
c
\end{array}}.\] But it is a two-variable homogenous system for the transformed variable $\bm{y}$, where
\begin{equation*}
\bm{y}=\bm{x}-\bm{x}^{*}=\bs{
\begin{array}{l}
k-k^{*}\\ 
c-c^{*}
\end{array}}.
\end{equation*}
The constant matrix $A$ of Section~\ref{sec:two} is  $\bm{J}^{*}$. The analysis of Section~\ref{sec:two} shows that
the properties of the steady state depend on the eigenvalues of $\bm{J}^{*}$. The four partial derivatives are
\begin{align*}
\pdw{\dot{k}}{k}{(k^{*},c^{*})}&=f'(k^{*}) -\d =\rho >0 \\
\pdw{\dot{k}}{c}{(k^{*},c^{*})}&=-1<0 \\
\pdw{\dot{c}}{k}{(k^{*},c^{*})}&=c\cdot f''\bp{k^{*}} <0 \\
\pdw{\dot{c}}{c}{(k^{*},c^{*})}&=f'(k^{*}) -\bp{\d +\rho} =0
\end{align*}
It follows that the Jacobian matrix can be written 
\begin{equation*}
\bm{J}^{*}=\bs{
\begin{array}{ll}
\rho  & -1  \\ 
c\cdot f''(k) & 0
\end{array}}
\end{equation*}
As shown by~\eqref{eq:DETL}, the product of the two eigenvalues is the determinant of $\bm{J}^{*}$:  \[\det(\bm{J}^{*})=c\cdot f''(k) <0.\] Therefore, the two eigenvalues have opposite sign. This property establishes that the steady state is a saddle point locally.

\end{document}